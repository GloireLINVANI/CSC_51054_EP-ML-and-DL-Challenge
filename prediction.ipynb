{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "id": "ee50916f625d443c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aggregating Preprocessed Data for Training and Testing - Simple Mean Aggregation of Embeddings",
   "id": "8e2e0ec837118471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def string_to_array(embedding_str):\n",
    "    \"\"\"\n",
    "    Converting string representation of embedding to numpy array.\n",
    "    Handles newlines and scientific notation.\n",
    "    \"\"\"\n",
    "    # Removing brackets and newlines\n",
    "    cleaned = embedding_str.strip('[]').replace('\\n', ' ')\n",
    "    return np.array([float(x) for x in cleaned.split()])\n",
    "\n",
    "\n",
    "def expand_embeddings(aggregated_df, loaded_df_from_csv=False):\n",
    "    \"\"\"\n",
    "    Expands BERT embeddings from the given DataFrame column into individual columns for each dimension of\n",
    "    the embedding. Optionally handles string representations of embeddings if the data is loaded from a CSV.\n",
    "    \"\"\"\n",
    "    print(\"Expanding embeddings...\")\n",
    "\n",
    "    # Getting embedding dimensions\n",
    "    if loaded_df_from_csv:\n",
    "        bert_embedding_dim = string_to_array(aggregated_df['BERT_Embedding'].iloc[0]).shape[0]\n",
    "        aggregated_df['BERT_Embedding'] = aggregated_df['BERT_Embedding'].apply(string_to_array)\n",
    "    else:\n",
    "        bert_embedding_dim = aggregated_df['BERT_Embedding'].iloc[0].shape[0]\n",
    "\n",
    "    # Creating column names\n",
    "    bert_columns = [f'BERT_{i}' for i in range(bert_embedding_dim)]\n",
    "\n",
    "    # Converting embeddings to DataFrames\n",
    "    bert_features = pd.DataFrame(\n",
    "        np.stack(aggregated_df['BERT_Embedding'].values),\n",
    "        columns=bert_columns\n",
    "    )\n",
    "    # Combining DataFrames\n",
    "    expanded_df = pd.concat([\n",
    "        aggregated_df.drop(columns=['BERT_Embedding']),\n",
    "        bert_features\n",
    "    ], axis=1)\n",
    "\n",
    "    return expanded_df, bert_columns"
   ],
   "id": "cbf199001dfbfb22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_large_dataset(filepath, chunk_size=10000, columns_to_load=None, mode='train'):\n",
    "    \"\"\"\n",
    "    Processing large training or test CSV files in chunks.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the CSV file\n",
    "        chunk_size (int): Number of rows to process in each chunk\n",
    "        columns_to_load (list): Columns to load from the CSV file\n",
    "        mode (str): Operating mode of the function ('train' or 'test'), which\n",
    "        affects the inclusion of the 'EventType' column; defaults to 'train'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Getting embedding dimensions from first row\n",
    "    first_chunk = next(pd.read_csv(filepath, nrows=1, usecols=['BERT_Embedding'], chunksize=1))\n",
    "    bert_dim = len(string_to_array(first_chunk['BERT_Embedding'].iloc[0]))\n",
    "    # Initializing aggregators\n",
    "    running_stats = {\n",
    "        'sums': {},  # Storing sums for mean calculations\n",
    "        'total_counts': {},  # Storing counts for mean calculations\n",
    "        'first_values': {}  # Storing first occurrences for period-wise constant features\n",
    "    }\n",
    "\n",
    "    # Reading and processing the CSV file in chunks\n",
    "    print(\"Processing chunks...\")\n",
    "    chunks_iterator = pd.read_csv(filepath, chunksize=chunk_size, usecols=columns_to_load)\n",
    "\n",
    "    for chunk in tqdm(chunks_iterator):\n",
    "\n",
    "        # Converting embeddings strings to arrays before processing\n",
    "        chunk['BERT_Embedding'] = chunk['BERT_Embedding'].apply(string_to_array)\n",
    "\n",
    "        # Processing each ID in the chunk\n",
    "        for id_group, group in chunk.groupby(['ID', 'PeriodID']):\n",
    "            # Initializing if this ID hasn't been seen before\n",
    "            if id_group not in running_stats['sums']:\n",
    "                running_stats['sums'][id_group] = {\n",
    "                    'Sentiment_joy': 0,\n",
    "                    'Sentiment_anger': 0,\n",
    "                    'Sentiment_fear': 0,\n",
    "                    'Sentiment_sadness': 0,\n",
    "                    'Sentiment_surprise': 0,\n",
    "                    'Sentiment_Score': 0,\n",
    "                    'Exclamation_Count': 0,\n",
    "                    'Question_Count': 0,\n",
    "                    'Uppercase_Ratio': 0,\n",
    "                    'Repeated_Char_Word_Ratio': 0,\n",
    "                    'Gives_Score': 0,\n",
    "                    'BERT_Embedding': np.zeros(bert_dim)\n",
    "                }\n",
    "                running_stats['first_values'][id_group] = {\n",
    "                    'Is_Key_Period': group['Is_Key_Period'].iloc[0],\n",
    "                    'EventType': group['EventType'].iloc[0] if mode == 'train' else None,\n",
    "                    'PeriodID': group['PeriodID'].iloc[0],\n",
    "                    'ID': group['ID'].iloc[0]\n",
    "                }\n",
    "                running_stats['total_counts'][id_group] = 0\n",
    "\n",
    "            # Updating sums for mean calculations\n",
    "            n = len(group)\n",
    "            running_stats['total_counts'][id_group] += n\n",
    "\n",
    "            # Updating sums for each metric\n",
    "            running_stats['sums'][id_group]['Sentiment_joy'] += group['Sentiment_joy'].sum()\n",
    "            running_stats['sums'][id_group]['Sentiment_anger'] += group['Sentiment_anger'].sum()\n",
    "            running_stats['sums'][id_group]['Sentiment_fear'] += group['Sentiment_fear'].sum()\n",
    "            running_stats['sums'][id_group]['Sentiment_sadness'] += group['Sentiment_sadness'].sum()\n",
    "            running_stats['sums'][id_group]['Sentiment_surprise'] += group['Sentiment_surprise'].sum()\n",
    "            running_stats['sums'][id_group]['Sentiment_Score'] += group['Sentiment_Score'].sum()\n",
    "            running_stats['sums'][id_group]['Exclamation_Count'] += group['Exclamation_Count'].sum()\n",
    "            running_stats['sums'][id_group]['Question_Count'] += group['Question_Count'].sum()\n",
    "            running_stats['sums'][id_group]['Uppercase_Ratio'] += group['Uppercase_Ratio'].sum()\n",
    "            running_stats['sums'][id_group]['Repeated_Char_Word_Ratio'] += group['Repeated_Char_Word_Ratio'].sum()\n",
    "            running_stats['sums'][id_group]['Gives_Score'] += group['Gives_Score'].sum()\n",
    "\n",
    "            # Updating embedding sums\n",
    "            running_stats['sums'][id_group]['BERT_Embedding'] += np.sum(np.vstack(group['BERT_Embedding']), axis=0)\n",
    "\n",
    "        # Forcing garbage collection after each chunk\n",
    "        gc.collect()\n",
    "\n",
    "    # Computing final aggregated results\n",
    "    print(\"Computing final aggregations...\")\n",
    "    result_data = []\n",
    "\n",
    "    for id_group in running_stats['total_counts'].keys():\n",
    "        count = running_stats['total_counts'][id_group]\n",
    "\n",
    "        result_dict = {\n",
    "            'ID': running_stats['first_values'][id_group]['ID'],\n",
    "            'PeriodID': running_stats['first_values'][id_group]['PeriodID'],\n",
    "            'Tweet_Count': count,\n",
    "            'Is_Key_Period': running_stats['first_values'][id_group]['Is_Key_Period'],\n",
    "            'EventType': running_stats['first_values'][id_group]['EventType'],\n",
    "            'Sentiment_joy': running_stats['sums'][id_group]['Sentiment_joy'] / count,\n",
    "            'Sentiment_anger': running_stats['sums'][id_group]['Sentiment_anger'] / count,\n",
    "            'Sentiment_fear': running_stats['sums'][id_group]['Sentiment_fear'] / count,\n",
    "            'Sentiment_sadness': running_stats['sums'][id_group]['Sentiment_sadness'] / count,\n",
    "            'Sentiment_surprise': running_stats['sums'][id_group]['Sentiment_surprise'] / count,\n",
    "            'Sentiment_Score': running_stats['sums'][id_group]['Sentiment_Score'] / count,\n",
    "            'Exclamation_Count': running_stats['sums'][id_group]['Exclamation_Count'],\n",
    "            'Question_Count': running_stats['sums'][id_group]['Question_Count'],\n",
    "            'Uppercase_Ratio': running_stats['sums'][id_group]['Uppercase_Ratio'] / count,\n",
    "            'Repeated_Char_Word_Ratio': running_stats['sums'][id_group]['Repeated_Char_Word_Ratio'] / count,\n",
    "            'Gives_Score': running_stats['sums'][id_group]['Gives_Score'],\n",
    "            'BERT_Embedding': running_stats['sums'][id_group]['BERT_Embedding'] / count\n",
    "        }\n",
    "\n",
    "        result_data.append(result_dict)\n",
    "\n",
    "    aggregated_df = pd.DataFrame(result_data)\n",
    "\n",
    "    return aggregated_df"
   ],
   "id": "f7cdb57fec65591c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_lagged_features(aggregated_df, loaded_df_from_csv=False):\n",
    "    \"\"\"\n",
    "    Compute lagged features for the aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    aggregated_df, bert_columns = expand_embeddings(aggregated_df, loaded_df_from_csv=loaded_df_from_csv)\n",
    "    # Adding a column for Match ID\n",
    "    aggregated_df['Match_ID'] = aggregated_df['ID'].str.split('_').str[0].astype(int)\n",
    "\n",
    "    # List of relevant columns for lagged features\n",
    "    columns_to_lag = [\n",
    "        'Sentiment_joy', 'Sentiment_anger', 'Sentiment_fear', 'Sentiment_sadness', 'Sentiment_surprise',\n",
    "        'Sentiment_Score', 'Exclamation_Count', 'Question_Count', 'Uppercase_Ratio',\n",
    "        'Repeated_Char_Word_Ratio', 'Gives_Score', 'Tweet_Count'\n",
    "    ]\n",
    "    # Computing lagged features per match\n",
    "    lagged_features = []\n",
    "    for col in columns_to_lag:\n",
    "        # Sorting within groups and computing differences\n",
    "        aggregated_df = (aggregated_df.groupby('Match_ID')\n",
    "                         .apply(lambda x: x.sort_values('PeriodID'))\n",
    "                         .reset_index(drop=True))\n",
    "\n",
    "        aggregated_df[f'{col}_lag1'] = aggregated_df.groupby('Match_ID')[col].shift(1)\n",
    "        aggregated_df[f'{col}_diff'] = aggregated_df[col] - aggregated_df[f'{col}_lag1']\n",
    "        lagged_features.extend([f'{col}_lag1', f'{col}_diff'])\n",
    "\n",
    "    prefix = 'BERT_'\n",
    "    # Computing the squared L2 norm of embedding changes\n",
    "    aggregated_df[f'{prefix}embedding_change'] = (\n",
    "        aggregated_df[bert_columns]\n",
    "        .diff(periods=1, axis=0)\n",
    "        .pow(2)\n",
    "        .sum(axis=1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "    lagged_features.extend([f'{prefix}embedding_change'])\n",
    "\n",
    "    aggregated_df[lagged_features] = aggregated_df[lagged_features].fillna(0)\n",
    "\n",
    "    return aggregated_df, bert_columns"
   ],
   "id": "d55f5a749a8a7bdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sophisticated Embedding Aggregation Methods  (Attention, Similarity and Adaptive Temperature Similarity)",
   "id": "91ad7a028af0b5f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class OptimizedEmbeddingAggregator:\n",
    "    \"\"\"\n",
    "    Memory-efficient GPU-accelerated embedding aggregation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=5000):\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        self.batch_size = batch_size\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def _chunked_matrix_multiply(self, mat1, mat2, chunk_size=128):\n",
    "        \"\"\"\n",
    "        Method that is performing matrix multiplication in chunks to avoid memory issues\n",
    "        \"\"\"\n",
    "        rows = mat1.size(0)\n",
    "        cols = mat2.size(1)\n",
    "        result = torch.zeros(rows, cols, device=self.device)\n",
    "\n",
    "        for i in range(0, rows, chunk_size):\n",
    "            end = min(i + chunk_size, rows)\n",
    "            result[i:end] = torch.mm(mat1[i:end], mat2)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            elif torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def attention_aggregate(self, embeddings_tensor):\n",
    "        \"\"\"\n",
    "        Memory-efficient attention-based aggregation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            n_tweets, embedding_dim = embeddings_tensor.shape\n",
    "            print(f\"Processing attention aggregation for {n_tweets} tweets\")\n",
    "\n",
    "            if n_tweets <= 128:\n",
    "                scores = torch.mm(embeddings_tensor, embeddings_tensor.t())\n",
    "                scores = scores / math.sqrt(embedding_dim)\n",
    "                weights = torch.softmax(scores, dim=-1)\n",
    "                return torch.mm(weights.mean(dim=0).unsqueeze(0), embeddings_tensor).squeeze(0)\n",
    "\n",
    "            scores = self._chunked_matrix_multiply(\n",
    "                embeddings_tensor,\n",
    "                embeddings_tensor.t()\n",
    "            ) / math.sqrt(embedding_dim)\n",
    "\n",
    "            weights = torch.zeros_like(scores)\n",
    "            for i in range(0, n_tweets, 128):\n",
    "                end = min(i + 128, n_tweets)\n",
    "                weights[i:end] = torch.softmax(scores[i:end], dim=-1)\n",
    "\n",
    "            avg_weights = weights.mean(dim=0)\n",
    "            result = torch.mm(avg_weights.unsqueeze(0), embeddings_tensor).squeeze(0)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            elif torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "            return result\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error in attention aggregate: {str(e)}\")\n",
    "            return embeddings_tensor.mean(dim=0)\n",
    "\n",
    "    def similarity_aggregate(self, embeddings_tensor):\n",
    "        \"\"\"\n",
    "        Memory-efficient similarity-based aggregation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            n_tweets, embedding_dim = embeddings_tensor.shape\n",
    "            print(f\"Processing similarity aggregation for {n_tweets} tweets\")\n",
    "\n",
    "            if n_tweets <= 128:\n",
    "                normalized = embeddings_tensor / (embeddings_tensor.norm(dim=1, keepdim=True) + 1e-8)\n",
    "                similarities = torch.mm(normalized, normalized.t())\n",
    "                weights = torch.softmax(similarities.mean(dim=1), dim=0)\n",
    "                return torch.mm(weights.unsqueeze(0), embeddings_tensor).squeeze(0)\n",
    "\n",
    "            normalized = embeddings_tensor / (embeddings_tensor.norm(dim=1, keepdim=True) + 1e-8)\n",
    "            similarities = self._chunked_matrix_multiply(normalized, normalized.t())\n",
    "\n",
    "            mean_similarities = similarities.mean(dim=1)\n",
    "            weights = torch.softmax(mean_similarities, dim=0)\n",
    "\n",
    "            result = torch.mm(weights.unsqueeze(0), embeddings_tensor).squeeze(0)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            elif torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "            return result\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error in similarity aggregate: {str(e)}\")\n",
    "            return embeddings_tensor.mean(dim=0)\n",
    "\n",
    "    def adaptive_similarity_aggregate(self, embeddings_tensor):\n",
    "        \"\"\"\n",
    "        Memory-efficient adaptive similarity-based aggregation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            n_tweets, embedding_dim = embeddings_tensor.shape\n",
    "            print(f\"Processing adaptive similarity aggregation for {n_tweets} tweets\")\n",
    "\n",
    "            normalized = embeddings_tensor / (embeddings_tensor.norm(dim=1, keepdim=True) + 1e-8)\n",
    "            similarities = self._chunked_matrix_multiply(normalized, normalized.t())\n",
    "\n",
    "            mean_similarities = similarities.mean(dim=1)\n",
    "            sim_std = mean_similarities.std()\n",
    "            sim_mean = mean_similarities.mean()\n",
    "\n",
    "            sim_centered = mean_similarities - sim_mean\n",
    "            sim_skewness = torch.mean(torch.pow(sim_centered, 3)) / (torch.pow(sim_std, 3) + 1e-8)\n",
    "\n",
    "            base_temp = 0.1\n",
    "            variance_factor = 1.0 / (1.0 + sim_std)\n",
    "            size_factor = torch.log1p(torch.tensor(n_tweets, device=self.device)) / 10.0\n",
    "            skew_factor = 1.0 / (1.0 + torch.abs(sim_skewness))\n",
    "\n",
    "            adaptive_temp = base_temp * variance_factor * (1 + size_factor) * skew_factor\n",
    "            adaptive_temp = torch.clamp(adaptive_temp, min=0.01, max=0.5)\n",
    "\n",
    "            scaled_similarities = mean_similarities / adaptive_temp\n",
    "            weights = torch.softmax(scaled_similarities, dim=0)\n",
    "\n",
    "            result = torch.mm(weights.unsqueeze(0), embeddings_tensor).squeeze(0)\n",
    "            final_embedding = result / (result.norm() + 1e-8)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            elif torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "            return final_embedding\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error in adaptive similarity aggregate: {str(e)}\")\n",
    "            return embeddings_tensor.mean(dim=0)"
   ],
   "id": "44746b928f1dab96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class OptimizedDataProcessor:\n",
    "    \"\"\"\n",
    "    A class that efficiently processes large datasets with embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=3000, aggregation_method='attention'):\n",
    "        self.batch_size = batch_size\n",
    "        self.aggregation_method = aggregation_method\n",
    "        self.aggregator = OptimizedEmbeddingAggregator(batch_size=batch_size)\n",
    "\n",
    "    def process_large_dataset(self, filepath, emb_filepath, chunk_size=10000, columns_to_load=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Process a large dataset to aggregate embeddings using the specified method.\n",
    "        Assumes pre-computed embeddings are stored as numpy arrays.\n",
    "\n",
    "        :param filepath: Path to the CSV file containing the dataset.\n",
    "        :type filepath: str\n",
    "        :param emb_filepath: Path to the file containing pre-computed embeddings as a numpy array.\n",
    "        :type emb_filepath: str\n",
    "        :param chunk_size: Number of rows to read at a time from the CSV file;\n",
    "            defaults to 10000.\n",
    "        :type chunk_size: int, optional\n",
    "        :param columns_to_load: List of column names to load from the CSV file; if None,\n",
    "            all columns are loaded.\n",
    "        :type columns_to_load: list of str, optional\n",
    "        :param mode: Operating mode of the function, 'train' or 'test', which\n",
    "            affects the inclusion of the 'EventType' column; defaults to 'train'.\n",
    "        :type mode: str, optional\n",
    "\n",
    "        :return: A pandas DataFrame containing combined statistics of non-embedding features\n",
    "            along with processed embeddings based on the specified aggregation method.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        # Initial stats containers\n",
    "        running_stats = {\n",
    "            'sums': defaultdict(lambda: defaultdict(float)),\n",
    "            'total_counts': defaultdict(int),\n",
    "            'first_values': {}\n",
    "        }\n",
    "\n",
    "        # Loading embeddings\n",
    "        print(\"Memory-mapping embeddings file...\")\n",
    "        embeddings = np.load(emb_filepath, mmap_mode='r')\n",
    "\n",
    "        # Processing non-embedding features first\n",
    "        print(\"Processing non-embedding features...\")\n",
    "        non_embedding_columns = [col for col in columns_to_load if col not in ['BERT_Embedding']]\n",
    "        chunks_iterator = pd.read_csv(filepath, chunksize=chunk_size, usecols=non_embedding_columns)\n",
    "\n",
    "        for chunk in tqdm(chunks_iterator):\n",
    "            # Processing each ID in the chunk\n",
    "            for id_group, group in chunk.groupby(['ID', 'PeriodID']):\n",
    "                if id_group not in running_stats['first_values']:\n",
    "                    running_stats['first_values'][id_group] = {\n",
    "                        'Is_Key_Period': group['Is_Key_Period'].iloc[0],\n",
    "                        'EventType': group['EventType'].iloc[0] if mode == 'train' else None,\n",
    "                        'PeriodID': group['PeriodID'].iloc[0],\n",
    "                        'ID': group['ID'].iloc[0]\n",
    "                    }\n",
    "\n",
    "                n = len(group)\n",
    "                running_stats['total_counts'][id_group] += n\n",
    "\n",
    "                # Updating sums for non-embedding features\n",
    "                for col in ['Sentiment_joy', 'Sentiment_anger', 'Sentiment_fear',\n",
    "                            'Sentiment_sadness', 'Sentiment_surprise', 'Sentiment_Score',\n",
    "                            'Exclamation_Count', 'Question_Count', 'Uppercase_Ratio',\n",
    "                            'Repeated_Char_Word_Ratio', 'Gives_Score']:\n",
    "                    if col in group.columns:\n",
    "                        running_stats['sums'][id_group][col] += group[col].sum()\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        # Process embeddings\n",
    "        print(\"\\nProcessing embeddings...\")\n",
    "        current_idx = 0\n",
    "        accumulated_embeddings = defaultdict(list)\n",
    "\n",
    "        # First pass: Accumulating embeddings\n",
    "        print(\"Accumulating embeddings...\")\n",
    "        chunks_iterator = pd.read_csv(filepath, chunksize=self.batch_size,\n",
    "                                      usecols=['ID', 'PeriodID'])\n",
    "\n",
    "        for chunk in tqdm(chunks_iterator):\n",
    "            chunk_size = len(chunk)\n",
    "            chunk_embeddings = embeddings[current_idx:current_idx + chunk_size]\n",
    "\n",
    "            for (idx, row), emb in zip(chunk.iterrows(), chunk_embeddings):\n",
    "                id_key = (row['ID'], row['PeriodID'])\n",
    "                accumulated_embeddings[id_key].append(emb)\n",
    "\n",
    "            current_idx += chunk_size\n",
    "            gc.collect()\n",
    "\n",
    "        # Second pass: Processing accumulated embeddings\n",
    "        print(\"\\nProcessing accumulated embeddings...\")\n",
    "        bert_results = {}\n",
    "\n",
    "        for id_key, emb_list in tqdm(accumulated_embeddings.items()):\n",
    "            try:\n",
    "                # Stacking all embeddings for this ID\n",
    "                print(\"Stacking embeddings...\")\n",
    "                stacked_embeddings = np.stack(emb_list)\n",
    "                print(f\"Stacked embeddings shape: {stacked_embeddings.shape}\")\n",
    "                print(\"Creating embeddings tensor...\")\n",
    "                embeddings_tensor = torch.tensor(stacked_embeddings, dtype=torch.float32,\n",
    "                                                 device=self.aggregator.device)\n",
    "                print(\"Finished creating embeddings tensor\")\n",
    "\n",
    "                # Processing using specified aggregation method\n",
    "                if self.aggregation_method == 'attention':\n",
    "                    result = self.aggregator.attention_aggregate(embeddings_tensor)\n",
    "                elif self.aggregation_method == 'similarity':\n",
    "                    result = self.aggregator.similarity_aggregate(embeddings_tensor)\n",
    "                elif self.aggregation_method == 'adaptive temperature similarity':\n",
    "                    result = self.aggregator.adaptive_similarity_aggregate(embeddings_tensor)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown aggregation method: {self.aggregation_method}\")\n",
    "\n",
    "                bert_results[id_key] = result.cpu().numpy()\n",
    "\n",
    "                # Clearing memory\n",
    "                del embeddings_tensor\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing ID {id_key}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Clearing accumulated embeddings\n",
    "        del accumulated_embeddings\n",
    "        gc.collect()\n",
    "\n",
    "        # Combining all features\n",
    "        print(\"\\nCombining features...\")\n",
    "        result_data = []\n",
    "\n",
    "        for id_group in running_stats['total_counts'].keys():\n",
    "            count = running_stats['total_counts'][id_group]\n",
    "            id_val, period_id = id_group\n",
    "\n",
    "            result_dict = {\n",
    "                'ID': id_val,\n",
    "                'PeriodID': period_id,\n",
    "                'Tweet_Count': count,\n",
    "                'Is_Key_Period': running_stats['first_values'][id_group]['Is_Key_Period'],\n",
    "                'EventType': running_stats['first_values'][id_group]['EventType'],\n",
    "            }\n",
    "\n",
    "            # Adding averaged non-embedding features\n",
    "            for metric, sum_value in running_stats['sums'][id_group].items():\n",
    "                result_dict[metric] = sum_value / count\n",
    "\n",
    "            # Adding embeddings if available\n",
    "            if id_group in bert_results:\n",
    "                result_dict['BERT_Embedding'] = bert_results[id_group]\n",
    "            else:\n",
    "                print(f\"Warning: Missing embeddings for ID: {id_val}, Period: {period_id}\")\n",
    "                continue\n",
    "\n",
    "            result_data.append(result_dict)\n",
    "\n",
    "        return pd.DataFrame(result_data)\n",
    "\n",
    "    def prepare_full_pipeline(self, train_filepath, test_filepath, train_emb_filepath,\n",
    "                              test_emb_filepath, columns_to_load, **kwargs):\n",
    "        \"\"\"\n",
    "        Method that is running the complete new embeddings aggregation pipeline\n",
    "        \"\"\"\n",
    "        # Processing train and test data\n",
    "        print(\"Processing training data...\")\n",
    "        train_df = self.process_large_dataset(\n",
    "            train_filepath,\n",
    "            train_emb_filepath,\n",
    "            mode='train',\n",
    "            columns_to_load=columns_to_load + ['EventType']\n",
    "        )\n",
    "        train_df.to_csv(f\"backup_data/aggregated_df_train_{self.aggregation_method}.csv\", index=False)\n",
    "\n",
    "        print(\"\\nProcessing test data...\")\n",
    "        test_df = self.process_large_dataset(\n",
    "            test_filepath,\n",
    "            test_emb_filepath,\n",
    "            mode='test',\n",
    "            columns_to_load=columns_to_load\n",
    "        )\n",
    "        test_df.to_csv(f\"backup_data/aggregated_df_test_{self.aggregation_method}.csv\", index=False)\n",
    "\n",
    "        # Computing lagged features\n",
    "        print(\"\\nComputing lagged features...\")\n",
    "        train_df_with_lags, bert_cols = compute_lagged_features(train_df)\n",
    "        test_df_with_lags, _ = compute_lagged_features(test_df)\n",
    "\n",
    "        # Preparing final datasets\n",
    "        print(\"\\nPreparing final datasets...\")\n",
    "        X_train_val, X_val, y_train_val, y_val, X_train_full, y_train_full, X_test = (\n",
    "            prepare_train_and_test_data(\n",
    "                train_df_with_lags, test_df_with_lags, bert_cols, **kwargs\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'X_train_val': X_train_val,\n",
    "            'X_val': X_val,\n",
    "            'y_train_val': y_train_val,\n",
    "            'y_val': y_val,\n",
    "            'X_train_full': X_train_full,\n",
    "            'y_train_full': y_train_full,\n",
    "            'X_test': X_test,\n",
    "            'Test IDs': test_df_with_lags['ID']\n",
    "        }"
   ],
   "id": "80c903bee5468a45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_optimized_pipeline(train_filepath, test_filepath, train_emb_filepath, test_emb_filepath, columns_to_load,\n",
    "                           aggregation_method='attention'):\n",
    "    \"\"\"\n",
    "    Wrapper function to run the new embeddings aggregation pipeline\n",
    "    \"\"\"\n",
    "    processor = OptimizedDataProcessor(\n",
    "        batch_size=10000,\n",
    "        aggregation_method=aggregation_method\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        results = processor.prepare_full_pipeline(\n",
    "            train_filepath=train_filepath,\n",
    "            test_filepath=test_filepath,\n",
    "            train_emb_filepath=train_emb_filepath,\n",
    "            test_emb_filepath=test_emb_filepath,\n",
    "            columns_to_load=columns_to_load,\n",
    "            n_components=46\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        elif torch.backends.mps.is_available():\n",
    "            torch.mps.empty_cache()\n",
    "\n",
    "        return results\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(\"\\nGPU out of memory. Trying with smaller batch size...\")\n",
    "            # Retrying with smaller batch size\n",
    "            processor.batch_size = 1500\n",
    "            results = processor.prepare_full_pipeline(\n",
    "                train_filepath=train_filepath,\n",
    "                test_filepath=test_filepath,\n",
    "                train_emb_filepath=train_emb_filepath,\n",
    "                test_emb_filepath=test_emb_filepath,\n",
    "                columns_to_load=columns_to_load,\n",
    "                n_components=46\n",
    "            )\n",
    "            return results\n",
    "        else:\n",
    "            raise e"
   ],
   "id": "b143298f779be547",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing Training, Validation and Testing Data",
   "id": "e58e25d181117353"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_train_and_test_data(expanded_df_train, expanded_df_test, n_components=46):\n",
    "    \"\"\"\n",
    "    Preparing data for model training with dimensionality reduction and scaling.\n",
    "    \"\"\"\n",
    "    print(\"Preparing data for training...\")\n",
    "    # Here, because of the processing function, X_test has 'EventType' column, but it's filled with NaNs\n",
    "    columns_to_drop = ['ID', 'EventType', 'Match_ID', 'Sentiment_fear'] + (\n",
    "        ['GloVe_Embedding'] if 'GloVe_Embedding' in expanded_df_train.columns else [])\n",
    "    X_test = expanded_df_test.drop(columns=columns_to_drop)\n",
    "\n",
    "    X_train_full = expanded_df_train.drop(columns=columns_to_drop)\n",
    "    y_train_full = expanded_df_train['EventType']\n",
    "\n",
    "    X_train_val, X_val, y_train_val, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.3, random_state=42, stratify=y_train_full\n",
    "    )\n",
    "\n",
    "    columns_to_reduce = [col for col in X_train_val.columns if col != 'Is_Key_Period']\n",
    "\n",
    "    print(\"Reducing dimensionality...\")\n",
    "    pca_train_val = PCA(n_components=n_components)\n",
    "    pca_train_full = PCA(n_components=n_components)\n",
    "\n",
    "    X_train_val_reduced = pca_train_val.fit_transform(\n",
    "        X_train_val[columns_to_reduce])\n",
    "    X_train_full_reduced = pca_train_full.fit_transform(\n",
    "        X_train_full[columns_to_reduce])\n",
    "    X_val_reduced = pca_train_val.transform(X_val[columns_to_reduce])\n",
    "    X_test_reduced = pca_train_full.transform(X_test[columns_to_reduce])\n",
    "\n",
    "    # Replacing original columns with reduced features\n",
    "    X_train_val_reduced_columns = [f'PCA_{i}' for i in range(len(pca_train_val.explained_variance_ratio_))]\n",
    "    X_train_full_reduced_columns = [f'PCA_{i}' for i in range(len(pca_train_full.explained_variance_ratio_))]\n",
    "    X_train_val_df = pd.DataFrame(X_train_val_reduced, columns=X_train_val_reduced_columns,\n",
    "                                  index=X_train_val.index)\n",
    "    X_train_full_df = pd.DataFrame(X_train_full_reduced, columns=X_train_full_reduced_columns,\n",
    "                                   index=X_train_full.index)\n",
    "    X_val_df = pd.DataFrame(X_val_reduced, columns=X_train_val_reduced_columns, index=X_val.index)\n",
    "    X_test_df = pd.DataFrame(X_test_reduced, columns=X_train_full_reduced_columns, index=X_test.index)\n",
    "\n",
    "    X_train_full = pd.concat([X_train_full.drop(columns=columns_to_reduce), X_train_full_df],\n",
    "                             axis=1)\n",
    "    X_train_val = pd.concat([X_train_val.drop(columns=columns_to_reduce), X_train_val_df],\n",
    "                            axis=1)\n",
    "    X_val = pd.concat([X_val.drop(columns=columns_to_reduce), X_val_df], axis=1)\n",
    "    X_test = pd.concat([X_test.drop(columns=columns_to_reduce), X_test_df], axis=1)\n",
    "\n",
    "    # Scaling Features\n",
    "    print(\"Scaling features...\")\n",
    "    columns_to_scale = [col for col in X_train_val.columns if col != 'Is_Key_Period']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler_x_train_full = StandardScaler()\n",
    "    X_train_full[columns_to_scale] = scaler_x_train_full.fit_transform(X_train_full[columns_to_scale])\n",
    "    X_test[columns_to_scale] = scaler_x_train_full.transform(X_test[columns_to_scale])\n",
    "    X_train_val[columns_to_scale] = scaler.fit_transform(X_train_val[columns_to_scale])\n",
    "    X_val[columns_to_scale] = scaler.transform(X_val[columns_to_scale])\n",
    "\n",
    "    return X_train_val, X_val, y_train_val, y_val, X_train_full, y_train_full, X_test"
   ],
   "id": "b4d47e2e6019f7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_filepath = \"backup_data/train_preprocessed_data.csv\"  # Path to the preprocessed training data\n",
    "train_emb_filepath = \"backup_data/train_bert_embeddings.npy\"  # Path to the precomputed BERT embeddings for training data\n",
    "test_filepath = \"backup_data/test_preprocessed_data.csv\"  # Path to the preprocessed test data\n",
    "test_emb_filepath = \"backup_data/test_bert_embeddings.npy\"  # Path to the precomputed BERT embeddings for test data"
   ],
   "id": "dc76ac649edae754",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_to_load = ['ID', 'PeriodID', 'Sentiment_Score', 'Sentiment_anger',\n",
    "                   'Sentiment_fear', 'Sentiment_joy', 'Sentiment_sadness', 'Sentiment_surprise',\n",
    "                   'Exclamation_Count', 'Question_Count', 'Uppercase_Ratio', 'Repeated_Char_Word_Ratio',\n",
    "                   'Is_Key_Period', 'Gives_Score', 'BERT_Embedding']"
   ],
   "id": "4546e8244ca5f8f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Simple Mean Aggregation of Embeddings",
   "id": "13795c966c8b8131"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_train = process_large_dataset(train_filepath, columns_to_load=columns_to_load + ['EventType'])",
   "id": "a565fd7b3a1afc66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_test = process_large_dataset(test_filepath, columns_to_load=columns_to_load, mode='test')",
   "id": "50e9a7994aea1c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_train.to_csv(\"backup_data/aggregated_df_train.csv\", index=False)",
   "id": "bdabbffc80635f97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_test.to_csv(\"backup_data/aggregated_df_test.csv\", index=False)",
   "id": "172ef7150cb82e8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Uncomment the following cell to load the aggregated data from CSV files",
   "id": "49cf547038c1c98c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# aggregated_df_train = pd.read_csv(\"backup_data/aggregated_df_train.csv\")\n",
    "# aggregated_df_test = pd.read_csv(\"backup_data/aggregated_df_test.csv\")"
   ],
   "id": "253bcfe387f5f550",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "loaded_from_csv = False  # Flag to indicate wether the data was loaded from CSV",
   "id": "a23a5aadb796e953",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_train, bert_columns = compute_lagged_features(aggregated_df_train, loaded_df_from_csv=loaded_from_csv)",
   "id": "ef533bda0ae0b95e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_test, _ = compute_lagged_features(aggregated_df_test, loaded_df_from_csv=loaded_from_csv)",
   "id": "1595d97faa24063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_df_train.head()",
   "id": "97529b4cd746fb0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Preparing data for training\n",
    "X_train_val, X_val, y_train_val, y_val, X_train_full, y_train_full, X_test = prepare_train_and_test_data(\n",
    "    aggregated_df_train, aggregated_df_test, n_components=46\n",
    ")"
   ],
   "id": "2e12de9b2bcc929d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Uncomment the following cell to try the other embeddings aggregation pipeline (Attention, Similarity or Adaptive Temperature Similarity)",
   "id": "901c4a754ac647a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#aggregation_method = 'attention'",
   "id": "842637a27ded8dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# datasets = run_optimized_pipeline(train_filepath, test_filepath, train_emb_filepath, test_emb_filepath,\n",
    "#                                             columns_to_load, aggregation_method)"
   ],
   "id": "f3778a48e4c01978",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#X_train_val, X_val, y_train_val, y_val, X_train_full, y_train_full, X_test, test_ids = datasets.values()",
   "id": "da03f946293b4716",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_full.head()",
   "id": "d20588c321ae9d8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_val.shape, X_val.shape, X_train_full.shape, X_test.shape",
   "id": "e1242689b1bb25fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baseline Models",
   "id": "87c7f54a4ec8686a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_cross_val_scores(model, X, y):\n",
    "    \"\"\"\n",
    "    Get cross-validation scores for a given model.\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"Mean Cross validation Accuracy: {scores.mean()}\")\n",
    "    print(\"Individual Cross validation scores: \", scores)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Evaluate a trained model on provided data.\"\"\"\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(classification_report(y, predictions))"
   ],
   "id": "9b25792079bff0ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression",
   "id": "6713377f4faa12c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")"
   ],
   "id": "3c5a6d22af3448c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(logistic_model, X_train_val, y_train_val)",
   "id": "e85009ba3354d3f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "logistic_model.fit(X_train_val, y_train_val)",
   "id": "15673434b0148bf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(logistic_model, X_train_val, y_train_val)",
   "id": "244f24293018e025",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(logistic_model, X_val, y_val)",
   "id": "b6d5d18a5bc61f8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "a73bb61615338406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "afd708d07983f797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(rf_model, X_train_val, y_train_val)",
   "id": "2db2ff850a738cae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rf_model.fit(X_train_val, y_train_val)",
   "id": "671da60cf8683c23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(rf_model, X_train_val, y_train_val)",
   "id": "cfd39fe65c9ed022",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(rf_model, X_val, y_val)",
   "id": "e0190a43744c885a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM",
   "id": "b118d4c05e6ac992"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=30,\n",
    "    min_child_weight=1e-3,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.3,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "47a5addd79c4e5f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(lgb_model, X_train_val, y_train_val)",
   "id": "b0fcd045f683002a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgb_model.fit(\n",
    "    X_train_val, y_train_val,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[early_stopping(stopping_rounds=50)]  # Early stopping callback\n",
    ")"
   ],
   "id": "a38935c49b5f6278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(lgb_model, X_train_val, y_train_val)",
   "id": "ce0c0f29ecca8d80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(lgb_model, X_val, y_val)",
   "id": "f0656842a51bee66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost",
   "id": "a9b7bd4e9dabc4ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    min_child_weight=5,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.3,\n",
    "    gamma=1,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "bde560c6254d859",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(xgb_model, X_train_val, y_train_val)",
   "id": "c10a69974356b7f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_model.fit(\n",
    "    X_train_val, y_train_val,\n",
    "    eval_set=[(X_val, y_val)],  # Early stopping on the validation set\n",
    "    verbose=False\n",
    ")"
   ],
   "id": "1a6586936df64e23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(xgb_model, X_train_val, y_train_val)",
   "id": "6758591917e6aa46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(xgb_model, X_val, y_val)",
   "id": "244d7eb7e17859bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter Optimization",
   "id": "47d6d3882369f9b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def optimize_logistic_regression(X_train, y_train, cv=5, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Performing hyperparameter optimization for Logistic Regression.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels\n",
    "        cv: Number of cross-validation folds\n",
    "        n_jobs: Number of parallel jobs (-1 for all processors)\n",
    "    \"\"\"\n",
    "    # Defining scoring metrics\n",
    "    scoring = {\n",
    "        'f1': 'f1_weighted',\n",
    "        'accuracy': 'accuracy'\n",
    "    }\n",
    "\n",
    "    # Defining parameter grid with valid solver-penalty combinations\n",
    "    param_grid = [\n",
    "        # SAGA solver, supports all penalties including elasticnet\n",
    "        {\n",
    "            'solver': ['saga'],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'C': np.logspace(-4, 4, 20),\n",
    "            'class_weight': ['balanced', None, custom_weights],\n",
    "            'max_iter': [2000],\n",
    "            'tol': [1e-4]\n",
    "        },\n",
    "        # LBFGS solve, only supports l2 penalty\n",
    "        {\n",
    "            'solver': ['lbfgs'],\n",
    "            'penalty': ['l2'],\n",
    "            'C': np.logspace(-4, 4, 20),\n",
    "            'class_weight': ['balanced', None, custom_weights],\n",
    "            'max_iter': [2000],\n",
    "            'tol': [1e-4]\n",
    "        },\n",
    "        # LIBLINEAR solver, supports l1 and l2 penalties\n",
    "        {\n",
    "            'solver': ['liblinear'],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': np.logspace(-4, 4, 20),\n",
    "            'class_weight': ['balanced', None, custom_weights],\n",
    "            'max_iter': [2000],\n",
    "            'tol': [1e-4]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=LogisticRegression(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        refit='accuracy'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"\\nBest cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "    return grid_search.best_estimator_, results_df"
   ],
   "id": "72e3622a0ec322f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "logistic_model_optimized, logistic_results_df = optimize_logistic_regression(X_train_val, y_train_val)",
   "id": "b06c925f6b3a6ec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "counter_y_train_full = Counter(y_train_full)\n",
    "counter_y_train_full"
   ],
   "id": "2ceea68a4d3a720f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "custom_weights = {\n",
    "    0: counter_y_train_full[1] / counter_y_train_full[0],\n",
    "    1: 1\n",
    "}"
   ],
   "id": "4e502542bb04f935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_param_grid(model_name):\n",
    "    \"\"\"\n",
    "    Getting parameter grid for a given model among 'rf', 'lgb' and 'xgb'\n",
    "\n",
    "    Args:\n",
    "        model_name: Name of the model ('rf', 'lgb', 'xgb', or 'lr')\n",
    "    Returns:\n",
    "        Parameter grid dictionary or list of dictionaries\n",
    "    \"\"\"\n",
    "    class_weight_options = [custom_weights] + [None, 'balanced']\n",
    "\n",
    "    param_grids = {\n",
    "        'rf': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_samples_split': [10, 20, 30],\n",
    "            'min_samples_leaf': [8, 16, 24],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'class_weight': ['balanced', custom_weights, None]\n",
    "        },\n",
    "        'lgb': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 4],\n",
    "            'learning_rate': [0.01],\n",
    "            'num_leaves': [7, 15],\n",
    "            'min_child_samples': [40, 80],\n",
    "            'colsample_bytree': [0.6, 0.8],\n",
    "            'is_unbalance': [True, False],\n",
    "            'class_weight': class_weight_options,\n",
    "            'reg_alpha': [0.1, 0.5],\n",
    "            'reg_lambda': [0.1, 0.5]\n",
    "        },\n",
    "        'xgb': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 4],\n",
    "            'learning_rate': [0.01],\n",
    "            'min_child_weight': [3, 5],\n",
    "            'subsample': [0.6, 0.8],\n",
    "            'gamma': [0.3, 0.5],\n",
    "            'scale_pos_weight': [None, 1 / custom_weights[0]],\n",
    "            'reg_alpha': [0.1, 0.5],\n",
    "            'reg_lambda': [0.1, 0.5]\n",
    "        }\n",
    "    }\n",
    "    return param_grids[model_name]\n",
    "\n",
    "\n",
    "def optimize_model(X_train, y_train, model_type, cv=5, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Performing hyperparameter optimization for various models.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels\n",
    "        model_type: Type of model ('rf', 'lgb'  or 'xgb')\n",
    "        cv: Number of cross-validation folds\n",
    "        n_jobs: Number of parallel jobs (-1 for all processors)\n",
    "    \"\"\"\n",
    "    model_classes = {\n",
    "        'rf': RandomForestClassifier(random_state=42),\n",
    "        'lgb': lgb.LGBMClassifier(random_state=42),\n",
    "        'xgb': xgb.XGBClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    param_grid = get_param_grid(model_type)\n",
    "\n",
    "    scoring = {\n",
    "        'f1': 'f1_weighted',\n",
    "        'accuracy': 'accuracy'\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_classes[model_type],\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        refit='accuracy',\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"\\nBest {model_type.upper()} parameters found:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"\\nBest cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    return grid_search.best_estimator_, pd.DataFrame(grid_search.cv_results_)"
   ],
   "id": "e72c6ade206bebb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models_to_optimize = ['rf', 'lgb', 'xgb']\n",
    "model_results = {}\n",
    "\n",
    "for model_type in models_to_optimize:\n",
    "    print(f\"\\nOptimizing {model_type.upper()}...\")\n",
    "    best_model, results = optimize_model(X_train_val, y_train_val, model_type)\n",
    "    model_results[model_type] = (best_model, results)"
   ],
   "id": "ed4fc1d70cc4149d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comparison_df = pd.concat(\n",
    "    [model_results[model_type][1].assign(model=model_type.upper()) for model_type in models_to_optimize]\n",
    ")"
   ],
   "id": "5e713a3d3d5b9fdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "comparison_df",
   "id": "7c23e853f808d753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "390462202c632e57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rf_model_optimized = model_results['rf'][0]",
   "id": "5abf10beb8ab64de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(rf_model_optimized, X_train_val, y_train_val)",
   "id": "69e367bd9d8b3423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rf_model_optimized.fit(X_train_val, y_train_val)",
   "id": "7fbf9ad20f2d7de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(rf_model_optimized, X_train_val, y_train_val)",
   "id": "6390e1b33298043",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(rf_model_optimized, X_val, y_val)",
   "id": "99e07a0b74dbee29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM",
   "id": "74e73ce465f37787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lgb_model_optimized = model_results['lgb'][0]",
   "id": "70756a6bad5b35db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(lgb_model_optimized, X_train_val, y_train_val)",
   "id": "e9456d825df842b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgb_model_optimized.fit(\n",
    "    X_train_val, y_train_val,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[early_stopping(stopping_rounds=50)]\n",
    ")"
   ],
   "id": "90ea314d05a521a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(lgb_model_optimized, X_train_val, y_train_val)",
   "id": "54dcfd007eee50ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(lgb_model_optimized, X_val, y_val)",
   "id": "7ea0870442fc8aae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost",
   "id": "fbee8931d5efc266"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "xgb_model_optimized = model_results['xgb'][0]",
   "id": "7967d14af4fad62a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_cross_val_scores(xgb_model_optimized, X_train_val, y_train_val)",
   "id": "95178dc69958d92f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_model_optimized.fit(\n",
    "    X_train_val, y_train_val,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")"
   ],
   "id": "3691193f91b6c49b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(xgb_model_optimized, X_train_val, y_train_val)",
   "id": "7257f29874ec9bfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(xgb_model_optimized, X_val, y_val)",
   "id": "8dcb8b2686d2b309",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Submission",
   "id": "cde65ed49da33c53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training on the whole training set before submission",
   "id": "d8244e783e66fad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_model = logistic_model",
   "id": "be737a7655ab339b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model.fit(\n",
    "    X_train_full, y_train_full,\n",
    ")"
   ],
   "id": "9d60622fca19c5f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions = best_model.predict(X_test)",
   "id": "d83aafa1e5aeeb58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pred_df = pd.DataFrame({'ID': aggregated_df_test['ID'], 'EventType': predictions})",
   "id": "2d6119c5a761782a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sorting the final DataFrame by the split components of ID\n",
    "pred_df['ID_First'] = pred_df['ID'].str.split('_').str[0].astype(int)\n",
    "pred_df['ID_Second'] = pred_df['ID'].str.split('_').str[1].astype(int)\n",
    "\n",
    "pred_df = pred_df.sort_values(by=['ID_First', 'ID_Second']).reset_index(drop=True)\n",
    "\n",
    "pred_df.drop(columns=['ID_First', 'ID_Second'], inplace=True)"
   ],
   "id": "5bfddb8995eab689",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pred_df",
   "id": "48eebc9358fb8d8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission_file = \"best_logistic_predictions.csv\"\n",
    "pred_df.to_csv(submission_file, index=False)"
   ],
   "id": "afc36fa8e2fce15d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_model(model, filepath, create_dir=True):\n",
    "    \"\"\"\n",
    "    Saving the trained model to disk\n",
    "    \"\"\"\n",
    "    directory = os.path.dirname(filepath)\n",
    "    if directory and create_dir:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    joblib.dump(model, filepath)\n",
    "\n",
    "\n",
    "def load_model(filepath):\n",
    "    \"\"\"\n",
    "    Loading the saved model from disk\n",
    "    \"\"\"\n",
    "    return joblib.load(filepath)"
   ],
   "id": "8d7c9ce8efdbe3b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Saving the best model\n",
    "model_filepath = 'models/best_logistic_regression_model.joblib'\n",
    "save_model(best_model, model_filepath)"
   ],
   "id": "7a8245bccc8d8fa1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
